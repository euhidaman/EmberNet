
======================================================================
TRIAL MODE: Running BOTH Stage 1 and Stage 2 sequentially
======================================================================

######################################################################
# STARTING STAGE 1
######################################################################

Auto-selected GPU 0 (78.8 GB free)

======================================================================
STAGE 1 TRAINING (TRIAL MODE)
======================================================================
Epochs: 1
Batch size: 1
Gradient accumulation: 4
Effective batch size: 4
Max samples per dataset: 10
Output directory: ./checkpoints/trial/stage1
Resume from: None
W&B logging: True
======================================================================


Loading weights:   0%|          | 0/208 [00:00<?, ?it/s]
Loading weights:   0%|          | 1/208 [00:00<00:00, 17924.38it/s, Materializing param=vision_model.embeddings.patch_embedding.bias]
Loading weights:   0%|          | 1/208 [00:00<00:00, 6423.13it/s, Materializing param=vision_model.embeddings.patch_embedding.bias] 
Loading weights:   1%|          | 2/208 [00:00<00:00, 6030.63it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|          | 2/208 [00:00<00:00, 4768.96it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 5121.25it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 4446.26it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 3923.58it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]   
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 3561.29it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 3830.41it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 3594.09it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 3824.59it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]  
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 3626.20it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 3853.04it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 3692.63it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 2966.27it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]      
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 2877.49it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 3066.01it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 2988.11it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 3150.06it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias] 
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 3073.20it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 3229.78it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 3159.66it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 3259.40it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 3194.24it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 3324.55it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 3262.68it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 3388.55it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 3327.68it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 3444.54it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 3386.51it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 3304.72it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]    
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 3249.82it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 3350.08it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 3300.00it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 3395.28it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]  
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 3348.60it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 3434.10it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 3387.25it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 3229.12it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]       
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 3188.25it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 3270.72it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 3233.26it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  11%|█         | 22/208 [00:00<00:00, 3010.50it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]  
Loading weights:  11%|█         | 22/208 [00:00<00:00, 2978.04it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 3048.67it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 3017.67it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 3089.54it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]      
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 3060.05it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 3127.37it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 3099.00it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 3136.65it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]  
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 3109.19it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 3169.14it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 3141.36it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight]
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 3199.67it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 3171.84it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 3231.36it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 3205.72it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight]
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 3049.89it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 3025.25it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 3079.59it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 3057.43it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight]
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 3013.76it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]    
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 2991.19it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 3046.98it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 3026.92it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 3077.52it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]  
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 3057.14it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 3107.42it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 3087.29it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 3136.78it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]       
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 3113.49it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 3153.16it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 3133.87it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 3060.89it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]  
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 3041.96it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 3082.83it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 3064.81it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 3036.05it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]      
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 3018.30it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 3063.55it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 3047.48it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|██        | 42/208 [00:00<00:00, 3085.78it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]  
Loading weights:  20%|██        | 42/208 [00:00<00:00, 3068.95it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 3108.98it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 3092.72it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 3018.62it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 3002.41it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 3040.33it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 3025.13it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 2935.53it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 2920.82it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 2955.60it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 2941.53it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 2977.24it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]    
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 2958.08it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 2965.41it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 2941.05it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 2928.53it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]  
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 2904.40it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 2895.87it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 2881.40it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 2913.57it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]       
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 2901.63it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 2932.69it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 2920.33it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 2951.96it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]  
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 2940.24it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 2867.81it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 2855.85it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 2886.12it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]      
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 2875.24it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 2902.14it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 2891.29it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 2918.51it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]  
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 2907.42it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 2935.27it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 2924.45it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 2952.00it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 2941.31it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 2911.55it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 2900.56it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 2927.40it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 2917.35it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 2944.32it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 2934.12it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  31%|███       | 64/208 [00:00<00:00, 2958.19it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]    
Loading weights:  31%|███       | 64/208 [00:00<00:00, 2947.73it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 2873.57it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 2862.77it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 2889.57it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]  
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 2880.58it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 2852.95it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 2841.32it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 2867.67it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]       
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 2859.16it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 2884.46it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 2875.64it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 2899.99it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]  
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 2891.37it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 2915.48it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 2906.77it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 2929.30it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]      
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 2919.72it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 2926.72it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 2917.85it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 2940.33it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]  
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 2931.72it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 2953.93it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 2945.55it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 2911.78it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 2902.76it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 2909.67it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 2899.30it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 2920.04it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 2912.04it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 2933.24it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 2925.18it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 2910.21it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]    
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 2900.17it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 2920.52it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 2912.61it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 2929.41it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]  
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 2921.59it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 2943.79it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 2936.47it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|████      | 84/208 [00:00<00:00, 2935.23it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]       
Loading weights:  40%|████      | 84/208 [00:00<00:00, 2927.52it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 2928.38it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 2920.70it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 2909.63it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]  
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 2901.63it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 2920.33it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 2913.20it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 2932.40it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]      
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 2925.20it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 2944.42it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 2937.63it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 2945.51it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]  
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 2938.29it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 2910.65it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 2903.41it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 2923.26it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 2915.20it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 2932.40it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 2925.42it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 2943.35it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 2936.64it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 2946.05it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 2939.16it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 2957.12it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]    
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 2948.82it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 2943.99it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 2937.04it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 2954.07it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]  
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 2947.66it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 2894.14it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 2887.21it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 2903.98it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]      
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 2896.32it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 2912.81it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 2906.74it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 2923.32it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]  
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 2917.26it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 2848.98it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 2842.75it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 2858.41it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]      
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 2852.48it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 2866.68it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 2860.79it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 2876.51it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]  
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 2870.73it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 2886.58it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 2881.04it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 2897.03it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 2891.55it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 2907.49it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 2900.64it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 2915.86it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 2910.25it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 2925.47it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 2919.80it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 2935.15it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]    
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 2929.75it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 2945.22it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 2939.76it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 2952.19it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]  
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 2946.42it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 2962.68it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 2957.43it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 2909.42it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]       
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 2903.65it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 2905.50it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 2899.89it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 2915.18it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]  
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 2908.89it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 2923.53it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 2918.42it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 2930.64it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]      
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 2925.14it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 2939.38it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 2934.15it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 2948.37it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]  
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 2943.32it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 2956.36it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 2951.22it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 2964.76it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 2959.63it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 2912.02it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 2906.37it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 2920.68it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 2915.86it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 2928.76it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 2923.69it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 2935.82it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]    
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 2930.69it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 2937.54it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 2932.48it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 2945.33it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]  
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 2940.36it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 2938.84it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 2933.71it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 2946.44it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]       
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 2941.74it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 2934.25it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 2929.29it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 2942.37it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]  
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 2937.62it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 2923.09it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 2918.39it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 2930.92it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]      
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 2926.31it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 2930.58it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 2925.88it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 2938.05it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]  
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 2933.61it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 2945.62it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 2941.23it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 2936.00it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 2931.18it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 2943.25it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 2938.78it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 2951.00it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 2946.63it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 2958.73it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 2954.17it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 2919.29it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]    
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 2890.45it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 2854.54it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 2849.08it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 2860.53it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]  
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 2856.30it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 2867.29it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 2863.01it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 2871.31it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]       
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 2866.84it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 2877.71it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 2873.58it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 2884.85it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]  
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 2880.68it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 2891.88it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 2887.85it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 2899.04it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]      
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 2895.05it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 2904.96it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 2900.93it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 2912.02it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]  
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 2908.00it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 2918.81it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 2914.93it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 2903.97it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 2899.73it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 2909.88it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 2905.87it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 2852.05it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 2847.89it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 2858.51it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 2854.76it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 2865.22it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]    
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 2861.47it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 2871.83it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 2868.11it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 2878.43it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]  
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 2874.72it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 2880.01it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 2876.04it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 2886.03it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]      
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 2882.28it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 2892.62it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 2888.98it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 2890.83it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]  
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 2886.96it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 2897.00it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 2893.11it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 2901.60it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]      
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 2896.98it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 2904.08it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 2899.91it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 2884.41it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]  
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 2880.42it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 2889.88it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 2886.35it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 2896.14it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 2892.59it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 2901.56it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 2897.93it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 2877.61it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 2873.34it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 2882.24it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 2878.61it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 2887.84it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]    
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 2884.29it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 2893.77it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 2890.31it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 2899.63it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]  
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 2896.15it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 2902.83it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 2899.23it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 2909.32it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]       
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 2905.93it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 2915.28it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 2911.92it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 2874.70it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]  
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 2870.95it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 2878.75it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 2875.28it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 2864.55it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]      
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 2861.04it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 2869.85it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 2866.08it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 2874.95it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]  
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 2871.67it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 2880.70it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 2877.51it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 2886.46it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 2883.25it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 2892.11it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 2888.85it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 2897.26it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 2893.89it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 2894.52it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 2891.08it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 2895.36it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]    
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 2891.96it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 2900.60it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 2897.23it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 2905.93it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]  
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 2902.71it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 2911.42it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 2908.21it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 2886.02it/s, Materializing param=vision_model.head.attention.in_proj_bias]              
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 2882.63it/s, Materializing param=vision_model.head.attention.in_proj_bias]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 2891.20it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 2888.10it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 2896.90it/s, Materializing param=vision_model.head.attention.out_proj.bias] 
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 2893.82it/s, Materializing param=vision_model.head.attention.out_proj.bias]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 2885.65it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 2882.26it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 2891.39it/s, Materializing param=vision_model.head.layernorm.bias]           
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 2888.46it/s, Materializing param=vision_model.head.layernorm.bias]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 2897.92it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 2895.04it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 2904.00it/s, Materializing param=vision_model.head.mlp.fc1.bias]    
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 2901.00it/s, Materializing param=vision_model.head.mlp.fc1.bias]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 2910.20it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 2907.35it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 2916.71it/s, Materializing param=vision_model.head.mlp.fc2.bias]  
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 2913.86it/s, Materializing param=vision_model.head.mlp.fc2.bias]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 2923.19it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 2920.38it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 2929.79it/s, Materializing param=vision_model.head.probe]         
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 2926.94it/s, Materializing param=vision_model.head.probe]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 2933.08it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 2929.95it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 2937.25it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 2934.26it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 2928.27it/s, Materializing param=vision_model.post_layernorm.weight]
[1mSiglipVisionModel LOAD REPORT[0m from: google/siglip-base-patch16-224
Key                                                          | Status     |  | 
-------------------------------------------------------------+------------+--+-
text_model.embeddings.token_embedding.weight                 | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.bias   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.bias          | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.weight | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.weight        | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.bias     | UNEXPECTED |  | 
text_model.head.bias                                         | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.bias          | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.v_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.v_proj.bias     | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.weight        | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.bias     | UNEXPECTED |  | 
logit_bias                                                   | UNEXPECTED |  | 
logit_scale                                                  | UNEXPECTED |  | 
text_model.embeddings.position_embedding.weight              | UNEXPECTED |  | 
text_model.final_layer_norm.bias                             | UNEXPECTED |  | 
text_model.head.weight                                       | UNEXPECTED |  | 
text_model.final_layer_norm.weight                           | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
wandb: [wandb.login()] Loaded credentials for https://api.wandb.ai from /root/.netrc.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: setting up run a2unpla8
wandb: Tracking run with wandb version 0.25.0
wandb: Run data is saved locally in /root/.amtrak/EmberNet/wandb/run-20260225_184536-a2unpla8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run embernet_stage1
wandb: ⭐️ View project at https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet
wandb: 🚀 View run at https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet/runs/a2unpla8
[codecarbon WARNING @ 18:45:39] Multiple instances of codecarbon are allowed to run at the same time.
✓ Decoder initialized
Applying BitNet weight initialization...
✓ Initialized 499 BitLinear layers with BitNet-specific weights
✓ BitNet weights initialized
✓ EMA model initialized

Stage 1 Training:
  Trainable parameters: 14,865,408
  Total parameters: 840,804,992
  Trainable ratio: 1.77%


==================================================
EmberNet VLM Model Summary
==================================================

Vision Encoder (google/siglip-base-patch16-224):
  encoder: 92,884,224 params
  compressor: 2,363,904 params
  pooler: 2,412,288 params
  projector: 10,088,448 params
  total: 107,748,864 params

Language Decoder (BitNet MoE):
  Layers: 16
  Hidden size: 768
  Experts: 8 (top-2)
  Total params: 733,055,360

Total Parameters: 840,804,224
Trainable Parameters: 14,864,640

Image tokens: 64
Max sequence length: 4096
==================================================

Using BitNetStableOptimizer with LR=0.0001
✓ BitNet gradient scaler initialized
✓ Initialized Weights & Biases: EmberNet/embernet_stage1
  [viz] Plots directory : /root/.amtrak/EmberNet/checkpoints/trial/stage1/plots
  [viz] Plot interval   : every 50 steps
  [viz] Trial mode      : True
  [Trial Mode] Limiting to 10 samples per dataset
Index scan: Found 5 datasets for domain='general'
Loading llava_instruct_150k from snapshot directory...
  Loaded 30 samples from llava_instruct_150k.json in llava_instruct_150k
Loading sharegpt4v from snapshot directory...
  Loaded 30 samples from share-captioner_coco_lcs_sam_1246k_1107.json in sharegpt4v
Loading allava_instruct from snapshot directory...
  Loaded 30 samples from allava_laion/ALLaVA-Caption-LAION-4V.json in allava_instruct
Loading coco_captions from snapshot directory...
  Found 132495 COCO images on disk in 4 directories
  Loaded 547741 COCO captions
Loading conceptual_captions from disk: data/conceptual_captions
  [WARNING] conceptual_captions has only image URLs (no embedded images). Image loading will be slow and many URLs may be expired. Consider pre-downloading images or removing this dataset.
  [Trial] Limited to 10 samples for general (train)
  [Trial] Skipping Stage 1 validation dataset (saves major reload)
  [Trial] eval_interval auto-set to 10 (one pass per epoch)
✓ BitNet optimizer phase1_steps set to 6

======================================================================
Starting Stage 1 Training
======================================================================
Epochs: 1
Steps per epoch: 10
Total steps: 10
Batch size: 1
Gradient accumulation: 4
Effective batch size: 4
Learning rate: 0.0001
Using BitNet optimizer: True
BitNet phase1 steps: 6
BitNet phase2 LR factor: 0.1
Device: cuda:0

--- Token Statistics (per sample) ---
Total tokens:  2,048
  ├─ Image tokens: 64
  └─ Text tokens:  1,984

--- Token Statistics (per batch) ---
Total tokens:  2,048
  ├─ Image tokens: 64
  └─ Text tokens:  1,984

--- Total Training Tokens (all epochs) ---
Total tokens:  20,480
  ├─ Image tokens: 640
  └─ Text tokens:  19,840
======================================================================

wandb: updating run metadata
wandb: uploading history steps 0-0, summary, console lines 65-68
wandb: 
wandb: Run history:
wandb:        epoch/avg_loss ▁
wandb:          epoch/number ▁
wandb: epoch/window_avg_loss ▁
wandb: 
wandb: Run summary:
wandb:        epoch/avg_loss 10.53775
wandb:          epoch/number 1
wandb: epoch/window_avg_loss 10.53775
wandb: 
wandb: 🚀 View run embernet_stage1 at: https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet/runs/a2unpla8
wandb: ⭐️ View project at: https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260225_184536-a2unpla8/logs
  Flushing 2 partial accumulated gradient(s) at epoch end (expected when batches < grad_accum=4)

Epoch 1 Complete
  Cumulative Avg Loss : 10.5377
  Final Window Avg    : 10.5377  (last 10 batches)
  Valid batches       : 10 / 10

Saved checkpoint to checkpoints/trial/stage1/checkpoint_epoch_1.pt
  [viz] Epoch 1 plots updated — 43 PNG files → /root/.amtrak/EmberNet/checkpoints/trial/stage1/plots
  [Trial] Skipping hub push (save ~20s)
Saved checkpoint to checkpoints/trial/stage1/final_model.pt
  [viz] Final plots saved — 43 PNG files → /root/.amtrak/EmberNet/checkpoints/trial/stage1/plots

Training complete in 0.3 minutes
Best validation loss: N/A (no validation data or too few steps)
✓ Weights & Biases run completed
  [energy] Stage 1: 0.0107 kWh, 0.003939 kg CO₂

######################################################################
# STAGE 1 COMPLETE - Checkpoint: ./checkpoints/trial/stage1/final_model.pt
######################################################################


######################################################################
# STARTING STAGE 2
######################################################################

Auto-selected GPU 1 (78.8 GB free)

======================================================================
STAGE 2 TRAINING (TRIAL MODE)
======================================================================
Epochs: 1
Batch size: 1
Gradient accumulation: 4
Effective batch size: 4
Max samples per dataset: 10
Output directory: ./checkpoints/trial/stage2
Resume from: ./checkpoints/trial/stage1/final_model.pt
W&B logging: True
======================================================================


Loading weights:   0%|          | 0/208 [00:00<?, ?it/s]
Loading weights:   0%|          | 1/208 [00:00<00:00, 41943.04it/s, Materializing param=vision_model.embeddings.patch_embedding.bias]
Loading weights:   0%|          | 1/208 [00:00<00:00, 324.06it/s, Materializing param=vision_model.embeddings.patch_embedding.bias]  
Loading weights:   1%|          | 2/208 [00:00<00:00, 272.83it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|          | 2/208 [00:00<00:00, 246.45it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 357.40it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 342.60it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 432.87it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]   
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 406.02it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 486.15it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 380.11it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 435.36it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]  
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 432.74it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 483.57it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 468.50it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 528.77it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]      
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 520.76it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 572.24it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 569.37it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 608.97it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias] 
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 605.84it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 624.70it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 615.22it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 657.07it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 652.98it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 669.33it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 665.50it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 709.54it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 705.65it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 746.75it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 742.48it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 769.54it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]    
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 758.70it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 780.64it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 777.77it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 817.47it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]  
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 814.35it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 854.31it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 851.54it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 882.13it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]       
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 879.22it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 892.58it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 884.75it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  11%|█         | 22/208 [00:00<00:00, 917.29it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]  
Loading weights:  11%|█         | 22/208 [00:00<00:00, 913.83it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 936.23it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 927.75it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 941.24it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]      
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 938.36it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 962.46it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 959.45it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 980.70it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]  
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 977.64it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 1005.53it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 998.32it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight] 
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 1026.46it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 1005.57it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 1034.24it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 996.67it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight] 
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 998.46it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 995.71it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 1017.44it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 910.12it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight] 
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 919.00it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]    
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 909.14it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 927.32it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 924.24it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 922.10it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]  
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 917.45it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 939.21it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 937.20it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 945.78it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]       
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 943.73it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 965.25it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 963.35it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 985.16it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]  
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 983.32it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 1004.95it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 1003.07it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 1024.18it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]      
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 1022.22it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 1043.20it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 1041.24it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|██        | 42/208 [00:00<00:00, 1062.21it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]  
Loading weights:  20%|██        | 42/208 [00:00<00:00, 1060.28it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 1081.11it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 1079.15it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 1099.67it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 1097.44it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 1117.70it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 1115.72it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 1136.00it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 1133.90it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 1153.87it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 1151.81it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 1171.63it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]    
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 1169.28it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 1188.71it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 1186.63it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 1206.10it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]  
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 1204.06it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 1223.41it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 1221.34it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 1240.51it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]       
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 1238.42it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 1256.88it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 1254.72it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 1273.23it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]  
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 1271.02it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 1289.75it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 1287.57it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 1306.22it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]      
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 1304.10it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 1322.07it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 1319.82it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 1337.79it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]  
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 1313.73it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 1306.60it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 1304.06it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 1320.85it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 1304.13it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 1320.49it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 1318.39it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 1335.50it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 1333.42it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 1281.52it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 1275.69it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  31%|███       | 64/208 [00:00<00:00, 1289.82it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]    
Loading weights:  31%|███       | 64/208 [00:00<00:00, 1287.96it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 1296.56it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 1294.67it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 1301.12it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]  
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 1299.05it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 1312.88it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 1307.51it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 1312.94it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]       
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 1302.80it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 1316.14it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 1309.46it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 1322.61it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]  
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 1320.71it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 1325.96it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 1312.53it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 1325.85it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]      
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 1320.16it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 1333.80it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 1331.94it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 1346.59it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]  
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 1344.92it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 1358.17it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 1354.83it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 1368.56it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 1363.31it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 1365.45it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 1362.70it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 1345.48it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 1329.49it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 1339.53it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 1336.88it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 1300.62it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]    
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 1248.67it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 1254.00it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 1252.49it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 1264.31it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]  
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 1262.87it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 1275.16it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 1273.73it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|████      | 84/208 [00:00<00:00, 1280.70it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]       
Loading weights:  40%|████      | 84/208 [00:00<00:00, 1279.23it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 1291.30it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 1289.90it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 1301.89it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]  
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 1300.44it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 1312.42it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 1311.02it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 1323.02it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]      
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 1321.64it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 1332.67it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 1330.12it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 1342.06it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]  
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 1340.64it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 1352.91it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 1351.55it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 1363.85it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 1362.48it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 1374.63it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 1373.24it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 1385.44it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 1384.05it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 1395.82it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 1394.36it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 1406.38it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]    
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 1404.99it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 1417.02it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 1415.64it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 1427.59it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]  
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 1426.17it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 1438.10it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 1436.72it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 1448.34it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]      
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 1446.88it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 1458.65it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 1457.22it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 1469.04it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]  
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 1467.63it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 1479.35it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 1477.92it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 1489.62it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]      
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 1488.19it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 1499.75it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 1497.96it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 1509.43it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]  
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 1507.97it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 1519.44it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 1518.00it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 1529.44it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 1527.98it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 1539.33it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 1537.86it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 1549.24it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 1547.50it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 1558.71it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 1557.21it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 1568.39it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]    
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 1566.90it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 1578.07it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 1576.58it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 1587.75it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]  
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 1586.28it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 1597.43it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 1595.61it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 1606.64it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]       
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 1605.15it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 1616.23it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 1614.74it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 1625.83it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]  
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 1624.33it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 1635.31it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 1633.83it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 1644.84it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]      
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 1643.39it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 1653.77it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 1652.26it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 1663.09it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]  
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 1661.59it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 1672.36it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 1670.83it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 1681.53it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 1679.94it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 1690.55it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 1688.99it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 1699.04it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 1697.46it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 1707.99it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 1706.42it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 1716.95it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]    
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 1715.39it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 1725.82it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 1724.26it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 1734.72it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]  
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 1733.13it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 1743.28it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 1741.69it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 1752.07it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]       
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 1750.49it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 1760.89it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 1759.32it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 1769.68it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]  
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 1768.11it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 1778.43it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 1776.85it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 1786.65it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]      
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 1785.07it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 1795.22it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 1793.66it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 1803.84it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]  
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 1802.27it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 1812.41it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 1810.87it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 1820.98it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 1819.41it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 1829.01it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 1827.34it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 1837.34it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 1835.74it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 1845.75it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 1844.14it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 1854.06it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]    
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 1852.47it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 1862.31it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 1860.70it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 1870.27it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]  
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 1868.59it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 1878.31it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 1876.70it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 1886.45it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]       
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 1884.82it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 1894.59it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 1892.97it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 1902.76it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]  
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 1901.17it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 1910.90it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 1908.89it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 1918.48it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]      
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 1916.88it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 1926.47it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 1924.88it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 1934.43it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]  
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 1932.82it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 1942.32it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 1940.68it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 1950.14it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 1948.19it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 1957.50it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 1955.87it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 1965.33it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 1963.68it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 1973.04it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 1971.39it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 1980.68it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]    
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 1979.04it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 1988.32it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 1986.41it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 1995.52it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]  
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 1993.86it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 2003.10it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 2001.46it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 2010.69it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]      
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 2009.05it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 2018.24it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 2016.60it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 2025.82it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]  
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 2024.18it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 2032.67it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 2030.93it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 2040.21it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]      
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 2038.60it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 2047.88it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 2046.30it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 2055.62it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]  
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 2054.06it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 2063.34it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 2061.74it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 2070.74it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 2069.08it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 2078.22it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 2076.60it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 2085.80it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 2084.19it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 2093.34it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 2091.72it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 2100.83it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]    
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 2099.21it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 2108.32it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 2106.70it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 2065.78it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]  
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 2064.18it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 2073.01it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 2071.48it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 2080.33it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]       
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 2078.78it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 2087.63it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 2086.09it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 2094.92it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]  
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 2093.33it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 2101.69it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 2100.02it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 2108.79it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]      
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 2107.25it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 2115.90it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 2114.34it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 2123.00it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]  
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 2121.45it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 2130.13it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 2128.59it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 2137.22it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 2135.36it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 2143.46it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 2141.80it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 2150.08it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 2148.42it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 2156.70it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 2155.06it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 2163.28it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]    
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 2161.64it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 2169.84it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 2168.19it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 2175.88it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]  
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 2174.22it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 2182.34it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 2180.63it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 2188.66it/s, Materializing param=vision_model.head.attention.in_proj_bias]              
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 2187.04it/s, Materializing param=vision_model.head.attention.in_proj_bias]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 2195.21it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 2193.57it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 2201.89it/s, Materializing param=vision_model.head.attention.out_proj.bias] 
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 2200.26it/s, Materializing param=vision_model.head.attention.out_proj.bias]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 2207.96it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 2206.30it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 2214.46it/s, Materializing param=vision_model.head.layernorm.bias]           
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 2212.83it/s, Materializing param=vision_model.head.layernorm.bias]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 2221.02it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 2219.42it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 2227.65it/s, Materializing param=vision_model.head.mlp.fc1.bias]    
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 2226.05it/s, Materializing param=vision_model.head.mlp.fc1.bias]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 2234.17it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 2232.57it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 2240.33it/s, Materializing param=vision_model.head.mlp.fc2.bias]  
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 2238.64it/s, Materializing param=vision_model.head.mlp.fc2.bias]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 2246.65it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 2243.56it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 2251.38it/s, Materializing param=vision_model.head.probe]         
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 2249.82it/s, Materializing param=vision_model.head.probe]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 2258.23it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 2256.73it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 2265.13it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 2263.59it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 2259.52it/s, Materializing param=vision_model.post_layernorm.weight]
[1mSiglipVisionModel LOAD REPORT[0m from: google/siglip-base-patch16-224
Key                                                          | Status     |  | 
-------------------------------------------------------------+------------+--+-
text_model.embeddings.token_embedding.weight                 | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.bias   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.bias          | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.weight | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.weight        | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.bias     | UNEXPECTED |  | 
text_model.head.bias                                         | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.bias          | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.v_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.v_proj.bias     | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.weight        | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.bias     | UNEXPECTED |  | 
logit_bias                                                   | UNEXPECTED |  | 
logit_scale                                                  | UNEXPECTED |  | 
text_model.embeddings.position_embedding.weight              | UNEXPECTED |  | 
text_model.final_layer_norm.bias                             | UNEXPECTED |  | 
text_model.head.weight                                       | UNEXPECTED |  | 
text_model.final_layer_norm.weight                           | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
wandb: setting up run ybfu6tmi
wandb: Tracking run with wandb version 0.25.0
wandb: Run data is saved locally in /root/.amtrak/EmberNet/wandb/run-20260225_184809-ybfu6tmi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run embernet_stage2
wandb: ⭐️ View project at https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet
wandb: 🚀 View run at https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet/runs/ybfu6tmi
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'lmms-lab/GQA' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
`trust_remote_code` is not supported anymore.
Please check that the Hugging Face dataset 'lmms-lab/GQA' isn't based on a loading script and remove `trust_remote_code`.
If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.
✓ Decoder initialized
Loading checkpoint from ./checkpoints/trial/stage1/final_model.pt
✓ EMA model initialized
✓ Gradient checkpointing enabled for decoder

Stage 2 Training:
  Trainable parameters: 723,343,232
  Total parameters: 840,804,992
  Trainable ratio: 86.03%


==================================================
EmberNet VLM Model Summary
==================================================

Vision Encoder (google/siglip-base-patch16-224):
  encoder: 92,884,224 params
  compressor: 2,363,904 params
  pooler: 2,412,288 params
  projector: 10,088,448 params
  total: 107,748,864 params

Language Decoder (BitNet MoE):
  Layers: 16
  Hidden size: 768
  Experts: 8 (top-2)
  Total params: 733,055,360

Total Parameters: 840,804,224
Trainable Parameters: 723,342,464

Image tokens: 64
Max sequence length: 4096
==================================================

Using BitNetStableOptimizer with LR=0.0003
✓ BitNet gradient scaler initialized
✓ Initialized Weights & Biases: EmberNet/embernet_stage2
  [viz] Plots directory : /root/.amtrak/EmberNet/checkpoints/trial/stage2/plots
  [viz] Plot interval   : every 50 steps
  [viz] Trial mode      : True
  [Trial Mode] Limiting to 10 samples per dataset
Index scan: Found 3 datasets for domain='spatial_scene'
Loading vqav2 from disk: data/vqav2
  [DataLoader] No 'train' split; using 'validation' from ['validation', 'testdev', 'test']
Loading visual_genome_region from snapshot directory...
  Loaded 30 samples from region_descriptions.json in visual_genome_region
Loading refcoco from disk: data/refcoco
  [DataLoader] No 'train' split; using 'val' from ['val', 'test', 'testA', 'testB']
  [Trial] Limited to 10 samples for spatial_scene (train)
Index scan: Found 5 datasets for domain='general'
Loading llava_instruct_150k from snapshot directory...
  [Cache HIT] llava_instruct_150k: 30 samples (skipping reload)
Loading sharegpt4v from snapshot directory...
  [Cache HIT] sharegpt4v: 30 samples (skipping reload)
Loading allava_instruct from snapshot directory...
  [Cache HIT] allava_instruct: 30 samples (skipping reload)
Loading coco_captions from snapshot directory...
  [Cache HIT] coco_captions: 547741 samples (skipping reload)
  [Cache HIT] conceptual_captions: 30 samples (skipping reload)
  [Trial] Limited to 10 samples for general (train)
Index scan: Found 2 datasets for domain='vision_ocr'
Loading textvqa from disk: data/textvqa
Loading docvqa from disk: data/docvqa
  [DataLoader] No 'train' split; using 'validation' from ['validation', 'test']
  [Trial] Limited to 10 samples for vision_ocr (train)
Index scan: Found 2 datasets for domain='spatial_reasoning'
Loading gqa from disk: data/gqa
  [CONTAMINATION WARNING] Dataset has only eval splits ['challenge']. Using the largest available split for training. lmms-eval scores for this dataset may be inflated.
  [DataLoader] gqa loaded from disk has no QA columns (cols=['id', 'image']); trying hub with config 'default'...
  Not a saved Dataset format; trying local repo load for gqa...
Loading nlvr2 from disk: data/nlvr2
  [DataLoader] No 'train' split; using 'balanced_dev' from ['balanced_dev', 'balanced_test_public', 'balanced_test_unseen', 'unbalanced_dev', 'unbalanced_test_unseen', 'unbalanced_test_public']
  [Trial] Limited to 10 samples for spatial_reasoning (train)
Index scan: Found 1 datasets for domain='vision_diagram'
Loading ai2d from disk: data/ai2d
  [CONTAMINATION WARNING] Dataset has only eval splits ['test']. Using the largest available split for training. lmms-eval scores for this dataset may be inflated.
  [Trial] Limited to 10 samples for vision_diagram (train)
Index scan: Found 2 datasets for domain='code_math_chart'
Loading chartqa from snapshot directory...
  Loaded 32719 samples from 5 parquet file(s) in chartqa
Loading plotqa from disk: data/plotqa
  [Trial] Limited to 10 samples for code_math_chart (train)
Index scan: Found 1 datasets for domain='code_math_formula'
Loading mathvista from disk: data/mathvista
  [CONTAMINATION WARNING] Dataset has only eval splits ['testmini', 'test']. Using the largest available split for training. lmms-eval scores for this dataset may be inflated.
  [Trial] Limited to 10 samples for code_math_formula (train)
Index scan: Found 2 datasets for domain='agentic_knowledge'
Loading okvqa from disk: data/okvqa
  [CONTAMINATION WARNING] Dataset has only eval splits ['val2014']. Using the largest available split for training. lmms-eval scores for this dataset may be inflated.
Loading aokvqa from disk: data/aokvqa
  [Trial] Limited to 10 samples for agentic_knowledge (train)
Index scan: Found 1 datasets for domain='agentic_reasoning'
Loading scienceqa from disk: data/scienceqa
  [Trial] Limited to 10 samples for agentic_reasoning (train)
  [Trial] Skipping Stage 2 validation dataset (saves major reload)
  [Trial] eval_interval auto-set to 86 (one pass per epoch)
✓ BitNet optimizer phase1_steps set to 51

======================================================================
Starting Stage 2 Training
======================================================================
Epochs: 1
Steps per epoch: 86
Total steps: 86
Batch size: 1
Gradient accumulation: 4
Effective batch size: 4
Learning rate: 0.0003
Using BitNet optimizer: True
BitNet phase1 steps: 51
BitNet phase2 LR factor: 0.1
Device: cuda:1

--- Token Statistics (per sample) ---
Total tokens:  2,048
  ├─ Image tokens: 64
  └─ Text tokens:  1,984

--- Token Statistics (per batch) ---
Total tokens:  2,048
  ├─ Image tokens: 64
  └─ Text tokens:  1,984

--- Total Training Tokens (all epochs) ---
Total tokens:  176,128
  ├─ Image tokens: 5,504
  └─ Text tokens:  170,624
======================================================================

wandb: updating run metadata
wandb: uploading wandb-summary.json; uploading config.yaml
wandb: 
wandb: Run history:
wandb:        epoch/avg_loss ▁
wandb:          epoch/number ▁
wandb: epoch/window_avg_loss ▁
wandb:  train/cumul_avg_loss ██▆▁
wandb:           train/epoch ▁▁▁▁
wandb:            train/loss █▄▁▇
wandb:              train/lr ▁▃▆█
wandb:            train/step ▁▃▆█
wandb: train/window_avg_loss ██▆▁
wandb: 
wandb: Run summary:
wandb:        epoch/avg_loss 8.9333
wandb:          epoch/number 1
wandb: epoch/window_avg_loss 7.86801
wandb:  train/cumul_avg_loss 9.16415
wandb:           train/epoch 1
wandb:            train/loss 10.6977
wandb:              train/lr 6e-05
wandb:            train/step 20
wandb: train/window_avg_loss 8.39117
wandb: 
wandb: 🚀 View run embernet_stage2 at: https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet/runs/ybfu6tmi
wandb: ⭐️ View project at: https://wandb.ai/aman-derax20-national-taiwan-university-of-science-and-t/EmberNet
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20260225_184809-ybfu6tmi/logs
[lmms_launcher] EmberNetLMMS imported successfully.
[lmms_launcher] Patched lmms_eval.models.get_model successfully.
[32m2026-02-25 18:52:45[0m | [1mINFO    [0m | [36mlmms_eval.__main__[0m:[36mcli_evaluate[0m:[36m311[0m - [1mVerbosity set to INFO[0m
[32m2026-02-25 18:52:47[0m | [1mINFO    [0m | [36mlmms_eval.__main__[0m:[36mcli_evaluate_single[0m:[36m400[0m - [1mEvaluation tracker args: {'output_path': 'checkpoints/trial/plots/benchmark_results/lmms_raw'}[0m
[32m2026-02-25 18:52:47[0m | [33m[1mWARNING [0m | [36mlmms_eval.__main__[0m:[36mcli_evaluate_single[0m:[36m430[0m - [33m[1m --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.[0m
[32m2026-02-25 18:52:47[0m | [1mINFO    [0m | [36mlmms_eval.__main__[0m:[36mcli_evaluate_single[0m:[36m480[0m - [1mSelected Tasks: ['ai2d', 'chartqa', 'pope', 'scienceqa_img', 'textvqa'][0m
[32m2026-02-25 18:52:47[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36msimple_evaluate[0m:[36m162[0m - [1mSetting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234[0m
[lmms_launcher] get_model intercepted → returning EmberNetLMMS
[32m2026-02-25 18:52:47[0m | [1mINFO    [0m | [36meval.embernet_lmms_adapter[0m:[36m__init__[0m:[36m146[0m - [1m[EmberNet] Loading model from: /root/.amtrak/EmberNet/checkpoints/trial/stage2/final_model.pt[0m
[32m2026-02-25 18:52:47[0m | [1mINFO    [0m | [36meval.embernet_lmms_adapter[0m:[36m__init__[0m:[36m147[0m - [1m[EmberNet] Device: cuda | dtype: bfloat16[0m

Loading weights:   0%|          | 0/208 [00:00<?, ?it/s]
Loading weights:   0%|          | 1/208 [00:00<00:00, 12052.60it/s, Materializing param=vision_model.embeddings.patch_embedding.bias]
Loading weights:   0%|          | 1/208 [00:00<00:00, 6678.83it/s, Materializing param=vision_model.embeddings.patch_embedding.bias] 
Loading weights:   1%|          | 2/208 [00:00<00:00, 6808.94it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|          | 2/208 [00:00<00:00, 5683.34it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 6291.46it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 5599.87it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 5955.70it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]   
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 5327.79it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 5632.96it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 5307.90it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 5566.43it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]  
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 5301.42it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 5618.09it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 5404.04it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 5705.57it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]      
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 5511.57it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 5737.76it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 5561.10it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 5787.64it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias] 
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 5630.69it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 3967.10it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 3893.12it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 4090.34it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 4010.17it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 4185.93it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 4121.70it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 4292.42it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 4231.18it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 4393.78it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 4332.36it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 4483.79it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]    
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 4427.00it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 4573.06it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 4514.57it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 4652.58it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]  
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 4597.34it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 4716.61it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 4660.07it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 4781.20it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]       
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 4727.04it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 4844.11it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 4791.93it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  11%|█         | 22/208 [00:00<00:00, 4905.88it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]  
Loading weights:  11%|█         | 22/208 [00:00<00:00, 4855.54it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 4968.27it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 4912.36it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 4569.58it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]      
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 4525.62it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 4381.85it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 4345.53it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 4436.25it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]  
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 4399.56it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 4483.22it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 4448.18it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight]
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 4536.66it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 4501.88it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 4585.49it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 4551.69it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight]
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 4632.37it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 4598.68it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 4675.76it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 4643.20it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight]
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 4697.03it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]    
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 4638.75it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 4437.71it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 4388.74it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 4439.52it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]  
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 4408.78it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 4151.60it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 4125.82it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 4187.21it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]       
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 4162.74it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 4225.14it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 4202.14it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 3969.41it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]  
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 3940.55it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 3990.68it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 3968.80it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 4022.73it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]      
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 3998.00it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 4051.04it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 4030.43it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|██        | 42/208 [00:00<00:00, 4081.39it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]  
Loading weights:  20%|██        | 42/208 [00:00<00:00, 4061.25it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 4112.44it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 4092.93it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 4143.08it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 4123.18it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 4171.50it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 4152.87it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 4058.61it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 4037.80it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 4083.27it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 4065.17it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 4110.22it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]    
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 4092.84it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 4138.89it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 4121.96it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 4164.49it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]  
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 4145.88it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 4187.57it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 4170.91it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 3979.13it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]       
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 3960.56it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 3999.97it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 3984.91it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 4018.25it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]  
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 3996.13it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 4020.19it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 4001.78it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 4034.16it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]      
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 4016.91it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 3826.55it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 3812.15it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 3845.98it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]  
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 3833.37it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 3870.43it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 3857.94it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 3894.85it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 3882.24it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 3918.35it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 3906.09it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 3942.02it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 3930.10it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 3878.37it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 3864.08it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  31%|███       | 64/208 [00:00<00:00, 3896.47it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]    
Loading weights:  31%|███       | 64/208 [00:00<00:00, 3884.63it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 3918.45it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 3906.82it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 3940.72it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]  
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 3928.87it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 3961.69it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 3950.33it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 3980.30it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]       
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 3968.89it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 3911.12it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 3898.10it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 3840.18it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]  
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 3827.67it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 3855.21it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 3839.50it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 3855.11it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]      
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 3841.72it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 3868.94it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 3858.65it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 3885.90it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]  
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 3875.86it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 3904.44it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 3894.10it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 3799.23it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 3788.26it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 3817.69it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 3808.10it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 3835.22it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 3825.58it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 3852.41it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 3843.12it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 3870.58it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]    
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 3861.27it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 3888.19it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 3879.22it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 3813.51it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]  
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 3802.76it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 3827.85it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 3819.32it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|████      | 84/208 [00:00<00:00, 3845.47it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]       
Loading weights:  40%|████      | 84/208 [00:00<00:00, 3837.09it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 3860.95it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 3851.89it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 3821.53it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]  
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 3812.00it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 3837.02it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 3828.53it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 3848.63it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]      
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 3835.79it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 3840.03it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 3827.08it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 3788.02it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]  
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 3778.99it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 3801.80it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 3791.72it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 3664.82it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 3656.62it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 3679.77it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 3672.74it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 3696.57it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 3689.75it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 3713.64it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 3706.97it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 3730.65it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]    
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 3723.96it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 3747.50it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 3740.82it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 3763.50it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]  
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 3756.79it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 3779.17it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 3772.37it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 3794.55it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]      
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 3787.63it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 3809.78it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 3802.87it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 3825.79it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]  
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 3819.03it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 3841.45it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 3834.77it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 3821.62it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]      
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 3814.87it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 3767.44it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 3755.45it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 3761.45it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]  
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 3751.77it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 3768.91it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 3760.92it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 3714.67it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 3706.85it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 3725.20it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 3719.05it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 3738.57it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 3732.28it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 3616.40it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 3609.58it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 3628.04it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]    
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 3622.19it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 3639.71it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 3633.52it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 3652.01it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]  
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 3646.36it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 3665.29it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 3659.56it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 3677.63it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]       
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 3671.97it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 3690.28it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 3684.79it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 3703.91it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]  
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 3698.21it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 3714.90it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 3709.15it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 3727.61it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]      
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 3722.15it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 3740.75it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 3735.13it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 3753.26it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]  
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 3747.71it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 3763.71it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 3756.09it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 3770.22it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 3763.99it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 3779.63it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 3774.06it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 3750.81it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 3744.38it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 3760.88it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 3755.26it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 3741.63it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]    
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 3735.87it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 3752.58it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 3747.09it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 3760.33it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]  
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 3754.92it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 3771.60it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 3766.43it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 3747.47it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]       
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 3741.50it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 3757.91it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 3752.55it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 3744.69it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]  
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 3739.33it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 3757.11it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 3750.62it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 3765.98it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]      
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 3761.14it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 3777.34it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 3772.40it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 3769.20it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]  
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 3763.74it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 3779.75it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 3774.69it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 3747.11it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 3741.72it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 3756.95it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 3751.97it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 3723.79it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 3715.46it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 3730.10it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 3725.45it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 3741.11it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]    
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 3736.46it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 3752.24it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 3747.71it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 3683.00it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]  
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 3678.42it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 3693.78it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 3689.41it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 3704.77it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]       
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 3699.39it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 3714.33it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 3709.92it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 3724.85it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]  
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 3720.58it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 3735.84it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 3731.70it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 3747.29it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]      
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 3743.13it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 3758.18it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 3754.05it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 3769.43it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]  
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 3765.15it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 3779.16it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 3774.99it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 3778.78it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 3774.45it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 3754.07it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 3749.71it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 3763.31it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 3759.04it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 3773.20it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 3769.04it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 3783.59it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]    
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 3779.33it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 3775.76it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 3771.48it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 3781.13it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]  
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 3774.24it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 3766.79it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 3761.98it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 3775.09it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]      
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 3770.99it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 3725.32it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 3720.97it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 3734.53it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]  
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 3730.57it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 3744.37it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 3740.45it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 3754.45it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]      
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 3750.62it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 3763.49it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 3759.61it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 3771.92it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]  
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 3767.77it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 3757.10it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 3753.20it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 3724.50it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 3720.37it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 3734.51it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 3730.93it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 3743.97it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 3740.10it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 3753.13it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 3749.24it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 3738.41it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]    
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 3734.40it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 3747.22it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 3743.50it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 3756.58it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]  
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 3752.86it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 3765.84it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 3762.27it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 3775.12it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]       
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 3771.50it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 3762.45it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 3755.99it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 3761.43it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]  
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 3755.16it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 3763.40it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 3758.28it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 3746.26it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]      
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 3742.55it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 3754.88it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 3751.34it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 3763.58it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]  
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 3760.08it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 3772.44it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 3768.90it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 3745.16it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 3741.48it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 3754.55it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 3751.13it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 3732.86it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 3729.33it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 3740.09it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 3736.57it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 3748.45it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]    
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 3745.04it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 3756.80it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 3753.35it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 3765.21it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]  
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 3761.83it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 3743.49it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 3739.97it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 3728.24it/s, Materializing param=vision_model.head.attention.in_proj_bias]              
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 3724.77it/s, Materializing param=vision_model.head.attention.in_proj_bias]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 3734.98it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 3729.13it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 3732.17it/s, Materializing param=vision_model.head.attention.out_proj.bias] 
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 3725.69it/s, Materializing param=vision_model.head.attention.out_proj.bias]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 3733.14it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 3729.32it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 3740.92it/s, Materializing param=vision_model.head.layernorm.bias]           
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 3737.82it/s, Materializing param=vision_model.head.layernorm.bias]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 3749.24it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 3746.00it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 3756.92it/s, Materializing param=vision_model.head.mlp.fc1.bias]    
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 3752.44it/s, Materializing param=vision_model.head.mlp.fc1.bias]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 3761.82it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 3757.71it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 3750.76it/s, Materializing param=vision_model.head.mlp.fc2.bias]  
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 3747.47it/s, Materializing param=vision_model.head.mlp.fc2.bias]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 3751.47it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 3748.29it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 3760.81it/s, Materializing param=vision_model.head.probe]         
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 3757.85it/s, Materializing param=vision_model.head.probe]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 3770.73it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 3767.81it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 3779.54it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 3776.49it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 3765.33it/s, Materializing param=vision_model.post_layernorm.weight]
[1mSiglipVisionModel LOAD REPORT[0m from: google/siglip-base-patch16-224
Key                                                          | Status     |  | 
-------------------------------------------------------------+------------+--+-
text_model.encoder.layers.{0...11}.self_attn.v_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.bias     | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.v_proj.bias     | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.bias          | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.weight | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.bias   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.bias     | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.bias          | UNEXPECTED |  | 
text_model.head.bias                                         | UNEXPECTED |  | 
logit_scale                                                  | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.weight        | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.weight        | UNEXPECTED |  | 
text_model.embeddings.position_embedding.weight              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.weight   | UNEXPECTED |  | 
text_model.final_layer_norm.bias                             | UNEXPECTED |  | 
text_model.embeddings.token_embedding.weight                 | UNEXPECTED |  | 
text_model.final_layer_norm.weight                           | UNEXPECTED |  | 
logit_bias                                                   | UNEXPECTED |  | 
text_model.head.weight                                       | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
✓ Decoder initialized
[32m2026-02-25 18:53:08[0m | [1mINFO    [0m | [36meval.embernet_lmms_adapter[0m:[36m__init__[0m:[36m172[0m - [1m[EmberNet] Loaded local checkpoint (step 22)[0m
[32m2026-02-25 18:53:14[0m | [1mINFO    [0m | [36meval.embernet_lmms_adapter[0m:[36m__init__[0m:[36m187[0m - [1m[EmberNet] Model ready — 840,804,992 parameters on cuda[0m
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m403[0m - [1mRunning on rank 0 (local rank 0)[0m
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for scienceqa_img, using default n_shot=0[0m
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for pope, using default n_shot=0[0m
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for chartqa, using default n_shot=0[0m
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.evaluator_utils[0m:[36mfrom_taskdict[0m:[36m91[0m - [1mNo metadata found in task config for ai2d, using default n_shot=0[0m
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for textvqa_val on rank 0...[0m

  0%|          | 0/5 [00:00<?, ?it/s]
100%|██████████| 5/5 [00:00<00:00, 5634.48it/s]
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for textvqa_test on rank 0...[0m

  0%|          | 0/5 [00:00<?, ?it/s]
100%|██████████| 5/5 [00:00<00:00, 6151.81it/s]
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for scienceqa_img on rank 0...[0m

  0%|          | 0/5 [00:00<?, ?it/s]
100%|██████████| 5/5 [00:00<00:00, 7869.24it/s]
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for pope on rank 0...[0m

  0%|          | 0/5 [00:00<?, ?it/s]
100%|██████████| 5/5 [00:00<00:00, 12550.28it/s]
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for chartqa on rank 0...[0m

  0%|          | 0/5 [00:00<?, ?it/s]
100%|██████████| 5/5 [00:00<00:00, 17418.21it/s]
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.api.task[0m:[36mbuild_all_requests[0m:[36m427[0m - [1mBuilding contexts for ai2d on rank 0...[0m

  0%|          | 0/5 [00:00<?, ?it/s]
100%|██████████| 5/5 [00:00<00:00, 14443.20it/s]
[32m2026-02-25 18:53:16[0m | [1mINFO    [0m | [36mlmms_eval.evaluator[0m:[36mevaluate[0m:[36m496[0m - [1mRunning generate_until requests[0m

EmberNet eval:   0%|          | 0/30 [00:00<?, ?it/s]
EmberNet eval:   3%|▎         | 1/30 [00:33<16:19, 33.78s/it]
EmberNet eval:   7%|▋         | 2/30 [01:06<15:22, 32.93s/it]
EmberNet eval:  10%|█         | 3/30 [01:38<14:40, 32.61s/it]
EmberNet eval:  13%|█▎        | 4/30 [02:10<14:01, 32.35s/it]
EmberNet eval:  17%|█▋        | 5/30 [02:42<13:29, 32.38s/it]
EmberNet eval:  20%|██        | 6/30 [03:15<12:59, 32.46s/it]
EmberNet eval:  23%|██▎       | 7/30 [03:48<12:30, 32.62s/it]
EmberNet eval:  27%|██▋       | 8/30 [04:21<11:59, 32.71s/it]
EmberNet eval:  30%|███       | 9/30 [04:53<11:25, 32.64s/it]
EmberNet eval:  33%|███▎      | 10/30 [05:27<10:58, 32.93s/it]
EmberNet eval:  37%|███▋      | 11/30 [05:29<07:27, 23.53s/it]
EmberNet eval:  40%|████      | 12/30 [05:31<05:07, 17.06s/it]
EmberNet eval:  43%|████▎     | 13/30 [05:34<03:33, 12.58s/it]
EmberNet eval:  47%|████▋     | 14/30 [05:36<02:31,  9.48s/it]
EmberNet eval:  50%|█████     | 15/30 [05:38<01:49,  7.30s/it]
EmberNet eval:  53%|█████▎    | 16/30 [05:55<02:22, 10.18s/it]
EmberNet eval:  57%|█████▋    | 17/30 [06:12<02:38, 12.16s/it]
EmberNet eval:  60%|██████    | 18/30 [06:29<02:43, 13.61s/it]
EmberNet eval:  63%|██████▎   | 19/30 [06:46<02:40, 14.61s/it]
EmberNet eval:  67%|██████▋   | 20/30 [07:02<02:32, 15.22s/it]
EmberNet eval:  70%|███████   | 21/30 [07:05<01:41, 11.32s/it]
EmberNet eval:  73%|███████▎  | 22/30 [07:07<01:08,  8.58s/it]
EmberNet eval:  77%|███████▋  | 23/30 [07:09<00:46,  6.67s/it]
EmberNet eval:  80%|████████  | 24/30 [07:11<00:31,  5.32s/it]
EmberNet eval:  83%|████████▎ | 25/30 [07:13<00:21,  4.39s/it]
EmberNet eval:  87%|████████▋ | 26/30 [07:16<00:14,  3.74s/it]
EmberNet eval:  90%|█████████ | 27/30 [07:18<00:09,  3.29s/it]
EmberNet eval:  93%|█████████▎| 28/30 [07:20<00:05,  2.98s/it]
EmberNet eval:  97%|█████████▋| 29/30 [07:22<00:02,  2.75s/it]
EmberNet eval: 100%|██████████| 30/30 [07:25<00:00,  2.60s/it]
EmberNet eval: 100%|██████████| 30/30 [07:25<00:00, 14.83s/it]

Postprocessing:   0%|          | 0/5 [00:00<?, ?it/s]
Postprocessing: 100%|██████████| 5/5 [00:00<00:00, 1718.13it/s]

Postprocessing:   0%|          | 0/5 [00:00<?, ?it/s]
Postprocessing: 100%|██████████| 5/5 [00:00<00:00, 2231.73it/s]

Postprocessing:   0%|          | 0/5 [00:00<?, ?it/s]
Postprocessing: 100%|██████████| 5/5 [00:00<00:00, 7549.14it/s]

Postprocessing:   0%|          | 0/5 [00:00<?, ?it/s]
Postprocessing: 100%|██████████| 5/5 [00:00<00:00, 11990.58it/s]

Postprocessing:   0%|          | 0/5 [00:00<?, ?it/s]
Postprocessing: 100%|██████████| 5/5 [00:00<00:00, 12129.28it/s]

Postprocessing:   0%|          | 0/5 [00:00<?, ?it/s]
Postprocessing: 100%|██████████| 5/5 [00:00<00:00, 6531.15it/s]
[32m2026-02-25 19:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mtextvqa_aggregate_submissions[0m:[36m67[0m - [1mSubmission file saved to /root/.amtrak/EmberNet/checkpoints/trial/plots/benchmark_results/lmms_raw/submissions/textvqa_submission_2026-02-25-19-00-44.json[0m
[32m2026-02-25 19:00:44[0m | [1mINFO    [0m | [36mutils[0m:[36mtextvqa_aggregate_submissions[0m:[36m67[0m - [1mSubmission file saved to /root/.amtrak/EmberNet/checkpoints/trial/plots/benchmark_results/lmms_raw/submissions/textvqa_submission_2026-02-25-19-00-44.json[0m
[32m2026-02-25 19:00:44[0m | [1mINFO    [0m | [36mlmms_eval.loggers.evaluation_tracker[0m:[36msave_results_aggregated[0m:[36m188[0m - [1mSaving results aggregated[0m
embernet (pretrained=/root/.amtrak/EmberNet/checkpoints/trial/stage2/final_model.pt,device=cuda,dtype=bfloat16), gen_kwargs: (), limit: 5.0, num_fewshot: None, batch_size: 1
|     Tasks     |Version|     Filter     |n-shot|      Metric       |   |Value|   |Stderr|
|---------------|-------|----------------|-----:|-------------------|---|-----|---|------|
|ai2d           |Yaml   |flexible-extract|     0|exact_match        |↑  |    0|±  |     0|
|chartqa        |Yaml   |none            |     0|relaxed_human_split|↑  |    0|±  |     0|
|chartqa        |Yaml   |none            |     0|relaxed_overall    |↑  |    0|±  |     0|
|pope           |Yaml   |none            |     0|pope_accuracy      |↑  |    0|±  |   N/A|
|pope           |Yaml   |none            |     0|pope_f1_score      |↑  |    0|±  |   N/A|
|pope           |Yaml   |none            |     0|pope_precision     |↑  |    0|±  |   N/A|
|pope           |Yaml   |none            |     0|pope_recall        |↑  |    0|±  |   N/A|
|pope           |Yaml   |none            |     0|pope_yes_ratio     |↑  |  0.6|±  |   N/A|
|scienceqa_img  |Yaml   |none            |     0|exact_match        |↑  |    0|±  |0.0000|
|textvqa        |    N/A|                |      |                   |   |     |   |      |
| - textvqa_test|Yaml   |none            |     0|submission         |↑  |N/A  |±  |   N/A|
| - textvqa_val |Yaml   |none            |     0|exact_match        |↑  |    0|±  |0.0000|
| - textvqa_val |Yaml   |none            |     0|submission         |↑  |N/A  |±  |   N/A|

Epoch 1/1 | Step 5 | Loss: 11.1801 | WinAvg(50): 10.3648 | CumAvg: 10.3648 | LR: 1.20e-05 | Time: 35.6s
Epoch 1/1 | Step 10 | Loss: 9.2788 | WinAvg(50): 10.3617 | CumAvg: 10.3617 | LR: 2.70e-05 | Time: 67.0s
Epoch 1/1 | Step 15 | Loss: 7.6637 | WinAvg(50): 9.7707 | CumAvg: 9.9428 | LR: 4.20e-05 | Time: 99.7s
Epoch 1/1 | Step 20 | Loss: 10.6977 | WinAvg(50): 8.3912 | CumAvg: 9.1642 | LR: 5.70e-05 | Time: 130.9s
  Flushing 2 partial accumulated gradient(s) at epoch end (expected when batches < grad_accum=4)

Epoch 1 Complete
  Cumulative Avg Loss : 8.9333
  Final Window Avg    : 7.8680  (last 50 batches)
  Valid batches       : 86 / 86

Saved checkpoint to checkpoints/trial/stage2/checkpoint_epoch_1.pt
  [viz] Epoch 1 plots updated — 67 PNG files → /root/.amtrak/EmberNet/checkpoints/trial/stage2/plots
  [Trial] Skipping hub push (save ~20s)
Saved checkpoint to checkpoints/trial/stage2/final_model.pt
  [viz] Final plots saved — 67 PNG files → /root/.amtrak/EmberNet/checkpoints/trial/stage2/plots

Training complete in 2.5 minutes
Best validation loss: N/A (val) | Final train loss: 10.6977
✓ Weights & Biases run completed
  [energy] Stage 2: 0.0368 kWh, 0.013570 kg CO₂

######################################################################
# STAGE 2 COMPLETE - Checkpoint: ./checkpoints/trial/stage2/final_model.pt
######################################################################


======================================================================
TRAINING COMPLETE!
======================================================================
Stages completed: [1, 2]
Final checkpoint: ./checkpoints/trial/stage2/final_model.pt
======================================================================


================================================================
  POST-TRAINING BENCHMARK EVALUATION
================================================================
  Mode    : TRIAL
  Tasks   : textvqa, ai2d, chartqa, scienceqa_img, pope
  Limit   : 5
  Checkpoint: checkpoints/trial/stage2/final_model.pt
  Plots → : /root/.amtrak/EmberNet/checkpoints/trial/plots/benchmark_results

  Running: /root/.amtrak/venv/bin/python /root/.amtrak/EmberNet/eval/lmms_launcher.py --model embernet --model_args pretrained=/root/.amtrak/EmberNet/checkpoints/trial/stage2/final_model.pt,device=cuda,dtype=bfloat16 ... (5 tasks)
  [auto_eval] _load_scores: scanned 48 JSON, accepted 24 with 'results' key → 9 task scores

  Benchmark scores extracted (9 tasks):
    ai2d                   0.0%
    chartqa                0.0%
    mme                    0.0%
    scienceqa_img          0.0%
    textvqa_test           0.0%
    textvqa_val            0.0%
    mmstar                 0.0%
    ocrbench               0.0%
    pope                   0.0%

================================================================
  Generating benchmark visualizations
================================================================

  4 benchmark plots saved:
    checkpoints/trial/plots/benchmark_results/spider/benchmark_expert_spider_trial_20260225_1900.png
    checkpoints/trial/plots/benchmark_results/task_scores/benchmark_task_bars_trial_20260225_1900.png
    checkpoints/trial/plots/benchmark_results/domain_analysis/benchmark_domain_heatmap_trial_20260225_1900.png
    checkpoints/trial/plots/benchmark_results/dashboard/benchmark_dashboard_trial_20260225_1900.png
  Scores JSON: checkpoints/trial/plots/benchmark_results/benchmark_scores_trial_20260225_1900.json

================================================================
  EVALUATION COMPLETE
================================================================

======================================================================
  POST-TRAINING: Generating all visualizations
======================================================================
  [viz] Loaded per-group LR history (86 steps) from checkpoints/trial/stage2/lr_groups.json

[§1] Training Dynamics
  ✓ plot-static-multi_stage_loss.png
  ✓ plot-static-components.png
  ✓ plot-static-per_dataset_heatmap.png
  ✓ plot-static-bitnet_two_phase_lr.png
  ✓ plot-static-per_group_lr.png
  ✓ plot-static-grad_norms.png
  ✓ plot-static-grad_flow_heatmap.png
  ✓ plot-static-clip_frequency.png
  ✓ plot-static-convergence_rate.png
  ✓ plot-static-training_efficiency.png
  ✓ plot-static-loss_vs_tokens.png
  ✓ plot-static-loss_spike_detection.png
  ✓ plot-static-gradient_clipping_rate_line.png
  ✓ plot-static-tokens_to_convergence.png
  ✓ plot-static-energy_vs_steps.png
  ✓ plot-static-co2_vs_steps.png
  ✓ plot-static-energy_per_token.png
  ✓ plot-static-stage_energy_comparison.png

[§2] Expert Analysis
  ✓ plot-static-selection_heatmap.png
  ✓ plot-static-cooccurrence.png
  ✓ plot-static-routing_by_dataset.png
  [WARNING] Sankey plot skipped (plotly not available): 

Kaleido requires Google Chrome to be installed.

Either download and install Chrome yourself following Google's instructions for your operating system,
or install it from your terminal by running:

    $ plotly_get_chrome


  ✓ plot-static-routing_sankey_snapshot.png
  ✓ plot-static-specialization_index.png
  ✓ plot-static-weight_sparsity_grid.png
  ✓ plot-static-output_variance.png
  ✓ plot-static-load_balancing.png
  ✓ plot-static-usage_violin.png
  ✓ plot-static-dead_expert_heatmap.png
  ✓ plot-static-per_expert.png
  ✓ plot-static-comparative.png
  ✓ plot-static-temporal_evolution.png
  ✓ plot-static-stacked_area_usage.png
  ✓ plot-static-routing_entropy_over_time.png

[§3] Architecture Visualizations
  ✓ plot-static-full_flowchart.png
  ✓ plot-static-moe_layer_detail.png
  ✓ plot-static-bitlinear_quant_flow.png
  ✓ plot-static-cross_modal.png
  ✓ plot-static-layerwise_grid.png
  ✓ plot-static-avg_attn_distance.png
  [WARNING] Sankey skipped: 

Kaleido requires Google Chrome to be installed.

Either download and install Chrome yourself following Google's instructions for your operating system,
or install it from your terminal by running:

    $ plotly_get_chrome


  ✓ plot-static-token_routing_sankey.png
  ✓ plot-static-expert_activation_timeline.png

[§4] Quantization Analysis
  ✓ plot-static-before_after_hist.png
  ✓ plot-static-layerwise_sparsity.png
  ✓ plot-static-magnitude_decay.png
  ✓ plot-static-4bit_dist.png
  ✓ plot-static-clipping_frequency.png
  ✓ plot-static-scale_boxplot.png
  ✓ plot-static-model_size_breakdown.png
  ✓ plot-static-effective_bitwidth.png
  ✓ plot-static-quant_pareto.png

[§5] Dataset Analysis
  ✓ plot-static-token_distribution.png
  ✓ plot-static-seq_length_violin.png
  ✓ plot-static-cumulative_tokens.png
  ✓ plot-static-domain_pie.png
  ✓ plot-static-mixing_schedule.png
  ✓ plot-static-expert_dataset_alignment.png
  ✓ plot-static-sample_grid.png
  ✓ plot-static-failure_cases.png

[§6] Performance Metrics
  ✓ plot-static-per_dataset.png
  ✓ plot-static-domain_accuracy.png
  ✓ plot-static-per_expert_target_acc.png
  ✓ plot-static-val_perplexity.png
  ✓ plot-static-ppl_by_position.png
  ✓ plot-static-accuracy_comparison.png
  ✓ plot-static-size_vs_performance.png
  ✓ plot-static-inference_speed.png
  ✓ plot-static-inference_energy_distribution.png
  ✓ plot-static-accuracy_vs_energy_pareto.png
  ✓ plot-static-model_efficiency_tradeoff.png

[§7] Stage Comparison & Ablations
  ✓ plot-static-loss_comparison.png
  ✓ plot-static-param_updates.png
  ✓ plot-static-routing_before_after.png
  ✓ plot-static-num_experts.png
  ✓ plot-static-routing_strategy.png
  ✓ plot-static-quantization_impact.png
  [viz] Generating 7 paper figures …

Loading weights:   0%|          | 0/208 [00:00<?, ?it/s]
Loading weights:   0%|          | 1/208 [00:00<00:00, 41943.04it/s, Materializing param=vision_model.embeddings.patch_embedding.bias]
Loading weights:   0%|          | 1/208 [00:00<00:00, 9868.95it/s, Materializing param=vision_model.embeddings.patch_embedding.bias] 
Loading weights:   1%|          | 2/208 [00:00<00:00, 7839.82it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|          | 2/208 [00:00<00:00, 6177.18it/s, Materializing param=vision_model.embeddings.patch_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 6180.21it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   1%|▏         | 3/208 [00:00<00:00, 5271.43it/s, Materializing param=vision_model.embeddings.position_embedding.weight]
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 5282.50it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]   
Loading weights:   2%|▏         | 4/208 [00:00<00:00, 4576.44it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.bias]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 4523.62it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   2%|▏         | 5/208 [00:00<00:00, 4132.32it/s, Materializing param=vision_model.encoder.layers.0.layer_norm1.weight]
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 4355.46it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]  
Loading weights:   3%|▎         | 6/208 [00:00<00:00, 4129.61it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.bias]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 3163.13it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   3%|▎         | 7/208 [00:00<00:00, 3066.97it/s, Materializing param=vision_model.encoder.layers.0.layer_norm2.weight]
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 3323.87it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]      
Loading weights:   4%|▍         | 8/208 [00:00<00:00, 3236.35it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.bias]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 3461.28it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   4%|▍         | 9/208 [00:00<00:00, 3377.06it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc1.weight]
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 3569.01it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias] 
Loading weights:   5%|▍         | 10/208 [00:00<00:00, 3487.99it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.bias]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 3668.39it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   5%|▌         | 11/208 [00:00<00:00, 3592.97it/s, Materializing param=vision_model.encoder.layers.0.mlp.fc2.weight]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 3767.34it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▌         | 12/208 [00:00<00:00, 3695.69it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.bias]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 3850.16it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   6%|▋         | 13/208 [00:00<00:00, 3780.49it/s, Materializing param=vision_model.encoder.layers.0.self_attn.k_proj.weight]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 3933.56it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 14/208 [00:00<00:00, 3865.72it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.bias]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 4008.06it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   7%|▋         | 15/208 [00:00<00:00, 3931.91it/s, Materializing param=vision_model.encoder.layers.0.self_attn.out_proj.weight]
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 4058.84it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]    
Loading weights:   8%|▊         | 16/208 [00:00<00:00, 3995.53it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.bias]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 3539.50it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   8%|▊         | 17/208 [00:00<00:00, 3491.66it/s, Materializing param=vision_model.encoder.layers.0.self_attn.q_proj.weight]
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 3603.70it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]  
Loading weights:   9%|▊         | 18/208 [00:00<00:00, 3558.68it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.bias]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 3666.69it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:   9%|▉         | 19/208 [00:00<00:00, 3623.01it/s, Materializing param=vision_model.encoder.layers.0.self_attn.v_proj.weight]
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 3721.65it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]       
Loading weights:  10%|▉         | 20/208 [00:00<00:00, 3678.57it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.bias]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 3777.36it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  10%|█         | 21/208 [00:00<00:00, 3735.39it/s, Materializing param=vision_model.encoder.layers.1.layer_norm1.weight]
Loading weights:  11%|█         | 22/208 [00:00<00:00, 3678.04it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]  
Loading weights:  11%|█         | 22/208 [00:00<00:00, 3611.39it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.bias]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 3618.22it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  11%|█         | 23/208 [00:00<00:00, 3567.51it/s, Materializing param=vision_model.encoder.layers.1.layer_norm2.weight]
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 3615.65it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]      
Loading weights:  12%|█▏        | 24/208 [00:00<00:00, 3577.23it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.bias]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 3625.53it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▏        | 25/208 [00:00<00:00, 3588.19it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc1.weight]
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 3489.10it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]  
Loading weights:  12%|█▎        | 26/208 [00:00<00:00, 3455.93it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.bias]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 3509.55it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight]
Loading weights:  13%|█▎        | 27/208 [00:00<00:00, 3477.01it/s, Materializing param=vision_model.encoder.layers.1.mlp.fc2.weight]
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 3516.18it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  13%|█▎        | 28/208 [00:00<00:00, 3484.99it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.bias]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 3362.31it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight]
Loading weights:  14%|█▍        | 29/208 [00:00<00:00, 3335.48it/s, Materializing param=vision_model.encoder.layers.1.self_attn.k_proj.weight]
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 3376.97it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  14%|█▍        | 30/208 [00:00<00:00, 3350.35it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.bias]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 3397.17it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight]
Loading weights:  15%|█▍        | 31/208 [00:00<00:00, 3371.80it/s, Materializing param=vision_model.encoder.layers.1.self_attn.out_proj.weight]
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 3417.64it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]    
Loading weights:  15%|█▌        | 32/208 [00:00<00:00, 3392.76it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.bias]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 3320.27it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▌        | 33/208 [00:00<00:00, 3296.78it/s, Materializing param=vision_model.encoder.layers.1.self_attn.q_proj.weight]
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 3341.68it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]  
Loading weights:  16%|█▋        | 34/208 [00:00<00:00, 3319.59it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.bias]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 3153.21it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 35/208 [00:00<00:00, 3133.49it/s, Materializing param=vision_model.encoder.layers.1.self_attn.v_proj.weight]
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 3174.36it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]       
Loading weights:  17%|█▋        | 36/208 [00:00<00:00, 3154.93it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.bias]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 3197.87it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 37/208 [00:00<00:00, 3179.78it/s, Materializing param=vision_model.encoder.layers.2.layer_norm1.weight]
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 3219.48it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]  
Loading weights:  18%|█▊        | 38/208 [00:00<00:00, 3201.05it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.bias]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 3241.93it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 39/208 [00:00<00:00, 3224.10it/s, Materializing param=vision_model.encoder.layers.2.layer_norm2.weight]
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 3263.10it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]      
Loading weights:  19%|█▉        | 40/208 [00:00<00:00, 3244.92it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.bias]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 3283.56it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|█▉        | 41/208 [00:00<00:00, 3266.16it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc1.weight]
Loading weights:  20%|██        | 42/208 [00:00<00:00, 3069.16it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]  
Loading weights:  20%|██        | 42/208 [00:00<00:00, 3053.36it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.bias]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 3085.79it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 43/208 [00:00<00:00, 3070.87it/s, Materializing param=vision_model.encoder.layers.2.mlp.fc2.weight]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 3105.74it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  21%|██        | 44/208 [00:00<00:00, 3090.81it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.bias]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 3125.72it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 45/208 [00:00<00:00, 3111.04it/s, Materializing param=vision_model.encoder.layers.2.self_attn.k_proj.weight]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 3144.82it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  22%|██▏       | 46/208 [00:00<00:00, 3130.23it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.bias]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 3161.76it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 47/208 [00:00<00:00, 3147.32it/s, Materializing param=vision_model.encoder.layers.2.self_attn.out_proj.weight]
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 3180.26it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]    
Loading weights:  23%|██▎       | 48/208 [00:00<00:00, 3166.26it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.bias]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 3198.42it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▎       | 49/208 [00:00<00:00, 3184.49it/s, Materializing param=vision_model.encoder.layers.2.self_attn.q_proj.weight]
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 3214.96it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]  
Loading weights:  24%|██▍       | 50/208 [00:00<00:00, 3201.07it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.bias]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 3232.29it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▍       | 51/208 [00:00<00:00, 3216.49it/s, Materializing param=vision_model.encoder.layers.2.self_attn.v_proj.weight]
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 3246.51it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]       
Loading weights:  25%|██▌       | 52/208 [00:00<00:00, 3232.99it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.bias]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 3262.47it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  25%|██▌       | 53/208 [00:00<00:00, 3249.26it/s, Materializing param=vision_model.encoder.layers.3.layer_norm1.weight]
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 3168.21it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]  
Loading weights:  26%|██▌       | 54/208 [00:00<00:00, 3155.68it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.bias]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 3182.72it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  26%|██▋       | 55/208 [00:00<00:00, 3170.60it/s, Materializing param=vision_model.encoder.layers.3.layer_norm2.weight]
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 3194.05it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]      
Loading weights:  27%|██▋       | 56/208 [00:00<00:00, 3180.26it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.bias]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 3206.18it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  27%|██▋       | 57/208 [00:00<00:00, 3192.31it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc1.weight]
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 3218.41it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]  
Loading weights:  28%|██▊       | 58/208 [00:00<00:00, 3207.08it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.bias]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 3233.01it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  28%|██▊       | 59/208 [00:00<00:00, 3221.26it/s, Materializing param=vision_model.encoder.layers.3.mlp.fc2.weight]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 3158.88it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 60/208 [00:00<00:00, 3126.19it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.bias]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 3153.18it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  29%|██▉       | 61/208 [00:00<00:00, 3142.19it/s, Materializing param=vision_model.encoder.layers.3.self_attn.k_proj.weight]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 3174.90it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|██▉       | 62/208 [00:00<00:00, 3164.86it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.bias]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 3195.22it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  30%|███       | 63/208 [00:00<00:00, 3185.12it/s, Materializing param=vision_model.encoder.layers.3.self_attn.out_proj.weight]
Loading weights:  31%|███       | 64/208 [00:00<00:00, 3183.46it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]    
Loading weights:  31%|███       | 64/208 [00:00<00:00, 3170.41it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.bias]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 3192.12it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  31%|███▏      | 65/208 [00:00<00:00, 3181.06it/s, Materializing param=vision_model.encoder.layers.3.self_attn.q_proj.weight]
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 3202.94it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]  
Loading weights:  32%|███▏      | 66/208 [00:00<00:00, 3189.77it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.bias]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 3120.55it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  32%|███▏      | 67/208 [00:00<00:00, 3107.99it/s, Materializing param=vision_model.encoder.layers.3.self_attn.v_proj.weight]
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 3131.80it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]       
Loading weights:  33%|███▎      | 68/208 [00:00<00:00, 3121.21it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.bias]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 3143.71it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  33%|███▎      | 69/208 [00:00<00:00, 3133.91it/s, Materializing param=vision_model.encoder.layers.4.layer_norm1.weight]
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 3156.22it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]  
Loading weights:  34%|███▎      | 70/208 [00:00<00:00, 3146.92it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.bias]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 3143.49it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  34%|███▍      | 71/208 [00:00<00:00, 3133.90it/s, Materializing param=vision_model.encoder.layers.4.layer_norm2.weight]
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 3154.17it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]      
Loading weights:  35%|███▍      | 72/208 [00:00<00:00, 3144.94it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.bias]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 3165.68it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  35%|███▌      | 73/208 [00:00<00:00, 3156.41it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc1.weight]
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 3177.15it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]  
Loading weights:  36%|███▌      | 74/208 [00:00<00:00, 3168.19it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.bias]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 3109.35it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  36%|███▌      | 75/208 [00:00<00:00, 3100.61it/s, Materializing param=vision_model.encoder.layers.4.mlp.fc2.weight]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 3120.79it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 76/208 [00:00<00:00, 3112.23it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.bias]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 3132.29it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  37%|███▋      | 77/208 [00:00<00:00, 3123.75it/s, Materializing param=vision_model.encoder.layers.4.self_attn.k_proj.weight]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 3142.92it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 78/208 [00:00<00:00, 3134.34it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.bias]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 3154.09it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 79/208 [00:00<00:00, 3145.80it/s, Materializing param=vision_model.encoder.layers.4.self_attn.out_proj.weight]
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 3135.25it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]    
Loading weights:  38%|███▊      | 80/208 [00:00<00:00, 3126.84it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.bias]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 3124.92it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 81/208 [00:00<00:00, 3116.67it/s, Materializing param=vision_model.encoder.layers.4.self_attn.q_proj.weight]
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 3135.24it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]  
Loading weights:  39%|███▉      | 82/208 [00:00<00:00, 3127.03it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.bias]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 3137.58it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|███▉      | 83/208 [00:00<00:00, 3129.32it/s, Materializing param=vision_model.encoder.layers.4.self_attn.v_proj.weight]
Loading weights:  40%|████      | 84/208 [00:00<00:00, 3149.05it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]       
Loading weights:  40%|████      | 84/208 [00:00<00:00, 3141.24it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.bias]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 3158.22it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████      | 85/208 [00:00<00:00, 3150.21it/s, Materializing param=vision_model.encoder.layers.5.layer_norm1.weight]
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 3134.18it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]  
Loading weights:  41%|████▏     | 86/208 [00:00<00:00, 3126.52it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.bias]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 3143.45it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 87/208 [00:00<00:00, 3135.11it/s, Materializing param=vision_model.encoder.layers.5.layer_norm2.weight]
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 3086.06it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]      
Loading weights:  42%|████▏     | 88/208 [00:00<00:00, 3078.75it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.bias]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 3095.81it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 89/208 [00:00<00:00, 3087.75it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc1.weight]
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 3105.36it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]  
Loading weights:  43%|████▎     | 90/208 [00:00<00:00, 3098.04it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.bias]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 3115.18it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 91/208 [00:00<00:00, 3108.06it/s, Materializing param=vision_model.encoder.layers.5.mlp.fc2.weight]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 3124.98it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  44%|████▍     | 92/208 [00:00<00:00, 3117.94it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.bias]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 3133.98it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▍     | 93/208 [00:00<00:00, 3126.69it/s, Materializing param=vision_model.encoder.layers.5.self_attn.k_proj.weight]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 3129.83it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  45%|████▌     | 94/208 [00:00<00:00, 3122.67it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.bias]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 3138.63it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 95/208 [00:00<00:00, 3131.65it/s, Materializing param=vision_model.encoder.layers.5.self_attn.out_proj.weight]
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 3117.55it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]    
Loading weights:  46%|████▌     | 96/208 [00:00<00:00, 3110.78it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.bias]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 3126.45it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 97/208 [00:00<00:00, 3119.66it/s, Materializing param=vision_model.encoder.layers.5.self_attn.q_proj.weight]
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 3135.35it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]  
Loading weights:  47%|████▋     | 98/208 [00:00<00:00, 3128.62it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.bias]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 3078.86it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 99/208 [00:00<00:00, 3072.34it/s, Materializing param=vision_model.encoder.layers.5.self_attn.v_proj.weight]
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 3087.75it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]      
Loading weights:  48%|████▊     | 100/208 [00:00<00:00, 3081.17it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.bias]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 3095.31it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▊     | 101/208 [00:00<00:00, 3088.86it/s, Materializing param=vision_model.encoder.layers.6.layer_norm1.weight]
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 3105.81it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]  
Loading weights:  49%|████▉     | 102/208 [00:00<00:00, 3099.71it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.bias]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 3118.62it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|████▉     | 103/208 [00:00<00:00, 3112.82it/s, Materializing param=vision_model.encoder.layers.6.layer_norm2.weight]
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 3131.22it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]      
Loading weights:  50%|█████     | 104/208 [00:00<00:00, 3125.50it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.bias]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 3143.77it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  50%|█████     | 105/208 [00:00<00:00, 3138.13it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc1.weight]
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 3156.48it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]  
Loading weights:  51%|█████     | 106/208 [00:00<00:00, 3150.77it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.bias]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 3127.77it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  51%|█████▏    | 107/208 [00:00<00:00, 3121.93it/s, Materializing param=vision_model.encoder.layers.6.mlp.fc2.weight]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 3139.97it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 108/208 [00:00<00:00, 3134.41it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.bias]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 3152.59it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  52%|█████▏    | 109/208 [00:00<00:00, 3147.06it/s, Materializing param=vision_model.encoder.layers.6.self_attn.k_proj.weight]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 3164.73it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 110/208 [00:00<00:00, 3158.36it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.bias]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 3153.10it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  53%|█████▎    | 111/208 [00:00<00:00, 3147.32it/s, Materializing param=vision_model.encoder.layers.6.self_attn.out_proj.weight]
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 3086.88it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]    
Loading weights:  54%|█████▍    | 112/208 [00:00<00:00, 3081.13it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.bias]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 3097.90it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  54%|█████▍    | 113/208 [00:00<00:00, 3092.60it/s, Materializing param=vision_model.encoder.layers.6.self_attn.q_proj.weight]
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 3109.13it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]  
Loading weights:  55%|█████▍    | 114/208 [00:00<00:00, 3103.79it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.bias]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 3119.33it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  55%|█████▌    | 115/208 [00:00<00:00, 3113.95it/s, Materializing param=vision_model.encoder.layers.6.self_attn.v_proj.weight]
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 3130.48it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]       
Loading weights:  56%|█████▌    | 116/208 [00:00<00:00, 3125.41it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.bias]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 3141.94it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  56%|█████▋    | 117/208 [00:00<00:00, 3136.80it/s, Materializing param=vision_model.encoder.layers.7.layer_norm1.weight]
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 3153.65it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]  
Loading weights:  57%|█████▋    | 118/208 [00:00<00:00, 3148.68it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.bias]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 3165.41it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  57%|█████▋    | 119/208 [00:00<00:00, 3160.38it/s, Materializing param=vision_model.encoder.layers.7.layer_norm2.weight]
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 3176.90it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]      
Loading weights:  58%|█████▊    | 120/208 [00:00<00:00, 3170.52it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.bias]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 3143.49it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  58%|█████▊    | 121/208 [00:00<00:00, 3137.84it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc1.weight]
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 3125.74it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]  
Loading weights:  59%|█████▊    | 122/208 [00:00<00:00, 3120.19it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.bias]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 3132.83it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  59%|█████▉    | 123/208 [00:00<00:00, 3125.98it/s, Materializing param=vision_model.encoder.layers.7.mlp.fc2.weight]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 3137.86it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|█████▉    | 124/208 [00:00<00:00, 3130.89it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.bias]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 3143.08it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  60%|██████    | 125/208 [00:00<00:00, 3137.03it/s, Materializing param=vision_model.encoder.layers.7.self_attn.k_proj.weight]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 3148.93it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 126/208 [00:00<00:00, 3143.50it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.bias]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 3110.92it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  61%|██████    | 127/208 [00:00<00:00, 3105.75it/s, Materializing param=vision_model.encoder.layers.7.self_attn.out_proj.weight]
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 3118.06it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]    
Loading weights:  62%|██████▏   | 128/208 [00:00<00:00, 3112.96it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.bias]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 3125.41it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▏   | 129/208 [00:00<00:00, 3120.47it/s, Materializing param=vision_model.encoder.layers.7.self_attn.q_proj.weight]
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 3133.06it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]  
Loading weights:  62%|██████▎   | 130/208 [00:00<00:00, 3127.98it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.bias]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 3140.53it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 131/208 [00:00<00:00, 3134.63it/s, Materializing param=vision_model.encoder.layers.7.self_attn.v_proj.weight]
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 3126.93it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]       
Loading weights:  63%|██████▎   | 132/208 [00:00<00:00, 3121.92it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.bias]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 3133.22it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 133/208 [00:00<00:00, 3127.06it/s, Materializing param=vision_model.encoder.layers.8.layer_norm1.weight]
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 3139.36it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]  
Loading weights:  64%|██████▍   | 134/208 [00:00<00:00, 3134.60it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.bias]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 3115.15it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▍   | 135/208 [00:00<00:00, 3110.53it/s, Materializing param=vision_model.encoder.layers.8.layer_norm2.weight]
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 3124.56it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]      
Loading weights:  65%|██████▌   | 136/208 [00:00<00:00, 3120.04it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.bias]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 3133.70it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▌   | 137/208 [00:00<00:00, 3128.58it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc1.weight]
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 3119.33it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]  
Loading weights:  66%|██████▋   | 138/208 [00:00<00:00, 3114.93it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.bias]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 3128.94it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 139/208 [00:00<00:00, 3124.59it/s, Materializing param=vision_model.encoder.layers.8.mlp.fc2.weight]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 3138.34it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  67%|██████▋   | 140/208 [00:00<00:00, 3133.92it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.bias]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 3132.48it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 141/208 [00:00<00:00, 3127.99it/s, Materializing param=vision_model.encoder.layers.8.self_attn.k_proj.weight]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 3141.65it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  68%|██████▊   | 142/208 [00:00<00:00, 3137.37it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.bias]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 3150.80it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 143/208 [00:00<00:00, 3146.55it/s, Materializing param=vision_model.encoder.layers.8.self_attn.out_proj.weight]
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 3135.96it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]    
Loading weights:  69%|██████▉   | 144/208 [00:00<00:00, 3131.54it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.bias]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 3145.03it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|██████▉   | 145/208 [00:00<00:00, 3140.83it/s, Materializing param=vision_model.encoder.layers.8.self_attn.q_proj.weight]
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 3153.95it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]  
Loading weights:  70%|███████   | 146/208 [00:00<00:00, 3149.77it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.bias]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 3163.06it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 147/208 [00:00<00:00, 3158.94it/s, Materializing param=vision_model.encoder.layers.8.self_attn.v_proj.weight]
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 3172.16it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]       
Loading weights:  71%|███████   | 148/208 [00:00<00:00, 3168.10it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.bias]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 3171.31it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 149/208 [00:00<00:00, 3167.07it/s, Materializing param=vision_model.encoder.layers.9.layer_norm1.weight]
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 3144.82it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]  
Loading weights:  72%|███████▏  | 150/208 [00:00<00:00, 3140.61it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.bias]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 3125.81it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 151/208 [00:00<00:00, 3121.45it/s, Materializing param=vision_model.encoder.layers.9.layer_norm2.weight]
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 3132.08it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]      
Loading weights:  73%|███████▎  | 152/208 [00:00<00:00, 3127.65it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.bias]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 3137.30it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▎  | 153/208 [00:00<00:00, 3130.47it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc1.weight]
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 3138.35it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]  
Loading weights:  74%|███████▍  | 154/208 [00:00<00:00, 3132.80it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.bias]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 3142.94it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▍  | 155/208 [00:00<00:00, 3138.77it/s, Materializing param=vision_model.encoder.layers.9.mlp.fc2.weight]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 3148.97it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 156/208 [00:00<00:00, 3144.65it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.bias]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 3154.70it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  75%|███████▌  | 157/208 [00:00<00:00, 3149.66it/s, Materializing param=vision_model.encoder.layers.9.self_attn.k_proj.weight]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 3115.11it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▌  | 158/208 [00:00<00:00, 3110.41it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.bias]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 3119.77it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  76%|███████▋  | 159/208 [00:00<00:00, 3115.66it/s, Materializing param=vision_model.encoder.layers.9.self_attn.out_proj.weight]
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 3125.09it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]    
Loading weights:  77%|███████▋  | 160/208 [00:00<00:00, 3121.05it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.bias]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 3130.67it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  77%|███████▋  | 161/208 [00:00<00:00, 3126.61it/s, Materializing param=vision_model.encoder.layers.9.self_attn.q_proj.weight]
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 3136.39it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]  
Loading weights:  78%|███████▊  | 162/208 [00:00<00:00, 3132.42it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.bias]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 3141.51it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  78%|███████▊  | 163/208 [00:00<00:00, 3137.45it/s, Materializing param=vision_model.encoder.layers.9.self_attn.v_proj.weight]
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 3147.03it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]      
Loading weights:  79%|███████▉  | 164/208 [00:00<00:00, 3143.01it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.bias]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 3152.32it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  79%|███████▉  | 165/208 [00:00<00:00, 3148.20it/s, Materializing param=vision_model.encoder.layers.10.layer_norm1.weight]
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 3157.23it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]  
Loading weights:  80%|███████▉  | 166/208 [00:00<00:00, 3153.34it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.bias]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 3161.97it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  80%|████████  | 167/208 [00:00<00:00, 3157.96it/s, Materializing param=vision_model.encoder.layers.10.layer_norm2.weight]
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 3143.37it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]      
Loading weights:  81%|████████  | 168/208 [00:00<00:00, 3139.56it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.bias]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 3128.16it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  81%|████████▏ | 169/208 [00:00<00:00, 3124.27it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc1.weight]
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 3118.06it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]  
Loading weights:  82%|████████▏ | 170/208 [00:00<00:00, 3114.31it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.bias]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 3123.83it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  82%|████████▏ | 171/208 [00:00<00:00, 3119.66it/s, Materializing param=vision_model.encoder.layers.10.mlp.fc2.weight]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 3128.64it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 172/208 [00:00<00:00, 3124.72it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.bias]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 3133.89it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  83%|████████▎ | 173/208 [00:00<00:00, 3130.00it/s, Materializing param=vision_model.encoder.layers.10.self_attn.k_proj.weight]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 3139.03it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▎ | 174/208 [00:00<00:00, 3135.32it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.bias]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 3144.26it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  84%|████████▍ | 175/208 [00:00<00:00, 3140.48it/s, Materializing param=vision_model.encoder.layers.10.self_attn.out_proj.weight]
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 3148.82it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]    
Loading weights:  85%|████████▍ | 176/208 [00:00<00:00, 3144.96it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.bias]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 3153.99it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  85%|████████▌ | 177/208 [00:00<00:00, 3150.32it/s, Materializing param=vision_model.encoder.layers.10.self_attn.q_proj.weight]
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 3139.61it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]  
Loading weights:  86%|████████▌ | 178/208 [00:00<00:00, 3135.90it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.bias]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 3143.77it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  86%|████████▌ | 179/208 [00:00<00:00, 3140.01it/s, Materializing param=vision_model.encoder.layers.10.self_attn.v_proj.weight]
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 3148.64it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]       
Loading weights:  87%|████████▋ | 180/208 [00:00<00:00, 3145.02it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.bias]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 3153.87it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  87%|████████▋ | 181/208 [00:00<00:00, 3150.17it/s, Materializing param=vision_model.encoder.layers.11.layer_norm1.weight]
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 3096.37it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]  
Loading weights:  88%|████████▊ | 182/208 [00:00<00:00, 3092.38it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.bias]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 3100.78it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 183/208 [00:00<00:00, 3097.26it/s, Materializing param=vision_model.encoder.layers.11.layer_norm2.weight]
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 3105.84it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]      
Loading weights:  88%|████████▊ | 184/208 [00:00<00:00, 3102.46it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.bias]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 3110.94it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 185/208 [00:00<00:00, 3107.33it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc1.weight]
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 3115.68it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]  
Loading weights:  89%|████████▉ | 186/208 [00:00<00:00, 3112.20it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.bias]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 3120.14it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|████████▉ | 187/208 [00:00<00:00, 3116.69it/s, Materializing param=vision_model.encoder.layers.11.mlp.fc2.weight]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 3124.92it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  90%|█████████ | 188/208 [00:00<00:00, 3121.48it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.bias]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 3129.72it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████ | 189/208 [00:00<00:00, 3126.23it/s, Materializing param=vision_model.encoder.layers.11.self_attn.k_proj.weight]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 3134.44it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  91%|█████████▏| 190/208 [00:00<00:00, 3131.04it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.bias]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 3138.72it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 191/208 [00:00<00:00, 3135.28it/s, Materializing param=vision_model.encoder.layers.11.self_attn.out_proj.weight]
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 3143.73it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]    
Loading weights:  92%|█████████▏| 192/208 [00:00<00:00, 3140.31it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.bias]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 3148.33it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 193/208 [00:00<00:00, 3144.93it/s, Materializing param=vision_model.encoder.layers.11.self_attn.q_proj.weight]
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 3112.86it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]  
Loading weights:  93%|█████████▎| 194/208 [00:00<00:00, 3109.11it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.bias]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 3116.52it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 195/208 [00:00<00:00, 3113.22it/s, Materializing param=vision_model.encoder.layers.11.self_attn.v_proj.weight]
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 3120.76it/s, Materializing param=vision_model.head.attention.in_proj_bias]              
Loading weights:  94%|█████████▍| 196/208 [00:00<00:00, 3117.31it/s, Materializing param=vision_model.head.attention.in_proj_bias]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 3125.24it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▍| 197/208 [00:00<00:00, 3121.93it/s, Materializing param=vision_model.head.attention.in_proj_weight]
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 3130.03it/s, Materializing param=vision_model.head.attention.out_proj.bias] 
Loading weights:  95%|█████████▌| 198/208 [00:00<00:00, 3126.71it/s, Materializing param=vision_model.head.attention.out_proj.bias]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 3134.85it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 199/208 [00:00<00:00, 3131.57it/s, Materializing param=vision_model.head.attention.out_proj.weight]
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 3139.54it/s, Materializing param=vision_model.head.layernorm.bias]           
Loading weights:  96%|█████████▌| 200/208 [00:00<00:00, 3136.33it/s, Materializing param=vision_model.head.layernorm.bias]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 3143.78it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 201/208 [00:00<00:00, 3140.51it/s, Materializing param=vision_model.head.layernorm.weight]
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 3128.97it/s, Materializing param=vision_model.head.mlp.fc1.bias]    
Loading weights:  97%|█████████▋| 202/208 [00:00<00:00, 3125.84it/s, Materializing param=vision_model.head.mlp.fc1.bias]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 3133.69it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 203/208 [00:00<00:00, 3130.03it/s, Materializing param=vision_model.head.mlp.fc1.weight]
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 3137.83it/s, Materializing param=vision_model.head.mlp.fc2.bias]  
Loading weights:  98%|█████████▊| 204/208 [00:00<00:00, 3134.58it/s, Materializing param=vision_model.head.mlp.fc2.bias]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 3142.43it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▊| 205/208 [00:00<00:00, 3139.13it/s, Materializing param=vision_model.head.mlp.fc2.weight]
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 3141.15it/s, Materializing param=vision_model.head.probe]         
Loading weights:  99%|█████████▉| 206/208 [00:00<00:00, 3138.04it/s, Materializing param=vision_model.head.probe]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 3144.78it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|█████████▉| 207/208 [00:00<00:00, 3141.56it/s, Materializing param=vision_model.post_layernorm.bias]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 3150.07it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 3146.87it/s, Materializing param=vision_model.post_layernorm.weight]
Loading weights: 100%|██████████| 208/208 [00:00<00:00, 3137.30it/s, Materializing param=vision_model.post_layernorm.weight]
[1mSiglipVisionModel LOAD REPORT[0m from: google/siglip-base-patch16-224
Key                                                          | Status     |  | 
-------------------------------------------------------------+------------+--+-
text_model.embeddings.token_embedding.weight                 | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.bias   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.bias          | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.out_proj.weight | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm2.weight        | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc2.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.bias              | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.q_proj.bias     | UNEXPECTED |  | 
text_model.head.bias                                         | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.bias          | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.mlp.fc1.weight            | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.v_proj.weight   | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.v_proj.bias     | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.layer_norm1.weight        | UNEXPECTED |  | 
text_model.encoder.layers.{0...11}.self_attn.k_proj.bias     | UNEXPECTED |  | 
logit_bias                                                   | UNEXPECTED |  | 
logit_scale                                                  | UNEXPECTED |  | 
text_model.embeddings.position_embedding.weight              | UNEXPECTED |  | 
text_model.final_layer_norm.bias                             | UNEXPECTED |  | 
text_model.head.weight                                       | UNEXPECTED |  | 
text_model.final_layer_norm.weight                           | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
✓ Decoder initialized
  [viz] EmberNetVLM loaded from ./checkpoints/trial/stage2/final_model.pt on cuda for paper figures
[fig1] Saved → plots/paper_figures/fig1_architecture_overview.pdf
  [viz] ✓ fig_architecture_overview
[fig2] Saved → plots/paper_figures/fig2_ternary_stats.png
  [viz] ✓ fig_ternary_stats
[fig3] Saved → plots/paper_figures/fig3_moe_routing.png
  [viz] ✓ fig_moe_routing
[fig4] Saved → plots/paper_figures/fig4_latency_energy.png
  [viz] ✓ fig_latency_energy
[fig_va_token_effects] Using synthetic trajectories: VA Refiner not attached to model
[fig5] Saved → plots/paper_figures/fig5_va_token_effects.png
  [viz] ✓ fig_va_token_effects
[fig6] Saved → plots/paper_figures/fig6_va_answer_level.png
  [viz] ✓ fig_va_answer_level
[fig7] Saved → plots/paper_figures/fig7_qualitative_grid.png
  [viz] ✓ fig_qualitative_grid
  [viz] 82 plots saved  |  report → plots/REPORT_20260225_192116.md
